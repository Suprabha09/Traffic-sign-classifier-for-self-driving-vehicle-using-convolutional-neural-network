# -*- coding: utf-8 -*-
"""RoadSign_classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iXgxt_8dVSxmITqqFH5INeMa76WApf1b
"""

#!wget --no-check-certificate \
#    https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB-Training_fixed.zip -O /tmp/GTSRB-Training_fixed.zip

"""The following python code will use the OS library to use Operating System libraries, giving you access to the file system, and the zipfile library allowing you to unzip the data."""

import os
import zipfile

#local_zip = '/content/drive/My Drive/tsrd-train.zip'
#zip_ref = zipfile.ZipFile(local_zip, 'r')
#zip_ref.extractall('/tmp/chinaSign')

#zip_ref.close()

from google.colab import drive
drive.mount('/content/drive')

# Directory with our training horse pictures
#train_horse_dir = os.path.join('/tmp/horse-or-human/horses')

# Directory with our training human pictures
#train_human_dir = os.path.join('/tmp/horse-or-human/humans')

import tensorflow as tf
model = tf.keras.models.Sequential([
    # Note the input shape is the desired size of the image 150x150 with 3 bytes color
    # This is the first convolution
    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(100, 100, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    # The second convolution
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # The third convolution
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # Flatten the results to feed into a DNN
    tf.keras.layers.Flatten(),
    # 512 neuron hidden layer
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(10, activation=tf.nn.softmax)
])

model.summary()

from tensorflow.keras.optimizers import RMSprop

model.compile(loss='categorical_crossentropy',
              optimizer=RMSprop(lr=0.001),
              metrics=['acc'])

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# All images will be rescaled by 1./255
train_datagen = ImageDataGenerator(rescale=1/255)

# Flow training images in batches of 128 using train_datagen generator
train_generator = train_datagen.flow_from_directory(
        '/content/drive/My Drive/tsrd-train',  # This is the source directory for training images
        target_size=(100, 100),  # All images will be resized to 150x150
        batch_size=109,
        # Since we use binary_crossentropy loss, we need binary labels
        class_mode='categorical')

history = model.fit_generator(
      train_generator,
      steps_per_epoch=10,  
      epochs=5,
      verbose=1)

import numpy as np
from google.colab import files
from keras.preprocessing import image

uploaded = files.upload()

for fn in uploaded.keys():
 
  # predicting images
  path = '/content/' + fn
  img = image.load_img(path, target_size=(100, 100))
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)
  print(classes[0])
  print(np.argmax(classes[0]))
  #if classes[0]>0.5:
  #  print(fn + " is ...")
  #else:
  #  print(fn + " is ....")